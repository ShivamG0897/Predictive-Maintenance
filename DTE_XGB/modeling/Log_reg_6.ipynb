{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sklearn as sk \n",
    "from scipy.stats import kurtosis, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failure = pd.read_csv('PdM_failures.csv')\n",
    "df_errors = pd.read_csv('PdM_errors.csv')\n",
    "df_machines = pd.read_csv('PdM_machines.csv')\n",
    "df_maint = pd.read_csv('PdM_maint.csv')\n",
    "df_telemetry = pd.read_csv('PdM_telemetry.csv')\n",
    "collated = pd.read_csv('collated.csv')\n",
    "df = df_telemetry.copy()\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['date'] = df['datetime'].dt.date\n",
    "df['hour'] = df['datetime'].dt.strftime('%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Mean Absolute Percentage Error (MAPE)\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Function to calculate Root Mean Squared Error (RMSE)\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "\n",
    "# Function to calculate cross-correlation between two signals\n",
    "def cross_correlation(x, y):\n",
    "    return np.correlate(x, y, mode='same')\n",
    "\n",
    "# Function to calculate energy of the signal\n",
    "def energy(x):\n",
    "    return np.sum(x**2)/100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fft_rotate'] = np.fft.fft(df['rotate'])\n",
    "df['fft_rotate_magnitude'] = np.abs(df['fft_rotate'])\n",
    "df['fft_rotate_phase'] = np.angle(df['fft_rotate'])\n",
    "df['fft_vibration'] = np.fft.fft(df['vibration'])\n",
    "df['fft_vibration_magnitude'] = np.abs(df['fft_vibration'])\n",
    "df['fft_vibration_phase'] = np.angle(df['fft_vibration'])\n",
    "df['fft_pressure'] = np.fft.fft(df['pressure'])\n",
    "df['fft_pressure_magnitude'] = np.abs(df['fft_pressure'])\n",
    "df['fft_pressure_phase'] = np.angle(df['fft_pressure'])\n",
    "df['fft_volt'] = np.fft.fft(df['volt'])\n",
    "df['fft_volt_magnitude'] = np.abs(df['fft_volt'])\n",
    "df['fft_volt_phase'] = np.angle(df['fft_volt'])\n",
    "\n",
    "\n",
    "df['signal_mag_area'] = (df['fft_rotate_magnitude'] + df['fft_vibration_magnitude'] + df['fft_pressure_magnitude'] + df['fft_volt_magnitude'])/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>machineID</th>\n",
       "      <th>rotate_min</th>\n",
       "      <th>rotate_max</th>\n",
       "      <th>rotate_&lt;lambda_0&gt;</th>\n",
       "      <th>rotate_&lt;lambda_1&gt;</th>\n",
       "      <th>rotate_&lt;lambda_2&gt;</th>\n",
       "      <th>rotate_median</th>\n",
       "      <th>rotate_mean</th>\n",
       "      <th>rotate_count</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_pressure_magnitude_energy_</th>\n",
       "      <th>fft_vibration_magnitude_mape_</th>\n",
       "      <th>fft_vibration_magnitude_rmse_</th>\n",
       "      <th>fft_vibration_magnitude_energy_</th>\n",
       "      <th>fft_volt_magnitude_mape_</th>\n",
       "      <th>fft_volt_magnitude_rmse_</th>\n",
       "      <th>fft_volt_magnitude_energy_</th>\n",
       "      <th>signal_mag_area_mape_</th>\n",
       "      <th>signal_mag_area_rmse_</th>\n",
       "      <th>signal_mag_area_energy_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>346.149335</td>\n",
       "      <td>527.349825</td>\n",
       "      <td>-0.790617</td>\n",
       "      <td>0.156417</td>\n",
       "      <td>78.750562</td>\n",
       "      <td>432.850118</td>\n",
       "      <td>440.515328</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>7.807908e+13</td>\n",
       "      <td>34.686905</td>\n",
       "      <td>8.337336e+06</td>\n",
       "      <td>1.251839e+13</td>\n",
       "      <td>50.344818</td>\n",
       "      <td>3.526230e+07</td>\n",
       "      <td>2.238566e+14</td>\n",
       "      <td>31.095042</td>\n",
       "      <td>1.566259e+06</td>\n",
       "      <td>4.417369e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>369.738792</td>\n",
       "      <td>543.802540</td>\n",
       "      <td>0.093926</td>\n",
       "      <td>0.364777</td>\n",
       "      <td>47.779860</td>\n",
       "      <td>444.667492</td>\n",
       "      <td>445.200094</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>8.793219e+07</td>\n",
       "      <td>78.885919</td>\n",
       "      <td>4.052344e+03</td>\n",
       "      <td>1.461031e+07</td>\n",
       "      <td>59.472938</td>\n",
       "      <td>1.233967e+04</td>\n",
       "      <td>1.327563e+08</td>\n",
       "      <td>21.840449</td>\n",
       "      <td>3.890529e+02</td>\n",
       "      <td>2.483783e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>382.648588</td>\n",
       "      <td>531.139800</td>\n",
       "      <td>-1.240765</td>\n",
       "      <td>0.072763</td>\n",
       "      <td>70.039863</td>\n",
       "      <td>461.496434</td>\n",
       "      <td>454.152365</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.933841e+07</td>\n",
       "      <td>52.362296</td>\n",
       "      <td>2.165231e+03</td>\n",
       "      <td>3.243161e+06</td>\n",
       "      <td>51.215365</td>\n",
       "      <td>6.231189e+03</td>\n",
       "      <td>4.040704e+07</td>\n",
       "      <td>26.900778</td>\n",
       "      <td>2.764719e+02</td>\n",
       "      <td>1.199865e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>327.243866</td>\n",
       "      <td>551.327283</td>\n",
       "      <td>0.721164</td>\n",
       "      <td>0.150727</td>\n",
       "      <td>43.058493</td>\n",
       "      <td>444.503545</td>\n",
       "      <td>447.758764</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>3.488463e+07</td>\n",
       "      <td>157.143177</td>\n",
       "      <td>3.017703e+03</td>\n",
       "      <td>4.651890e+06</td>\n",
       "      <td>43.115204</td>\n",
       "      <td>5.029131e+03</td>\n",
       "      <td>2.867365e+07</td>\n",
       "      <td>22.249581</td>\n",
       "      <td>2.267437e+02</td>\n",
       "      <td>1.382671e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>308.578855</td>\n",
       "      <td>539.732729</td>\n",
       "      <td>-0.368387</td>\n",
       "      <td>-0.589313</td>\n",
       "      <td>94.737470</td>\n",
       "      <td>461.502012</td>\n",
       "      <td>450.183235</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.594540e+07</td>\n",
       "      <td>90.424001</td>\n",
       "      <td>2.451706e+03</td>\n",
       "      <td>4.864141e+06</td>\n",
       "      <td>65.013985</td>\n",
       "      <td>5.540018e+03</td>\n",
       "      <td>3.057701e+07</td>\n",
       "      <td>25.863185</td>\n",
       "      <td>2.079213e+02</td>\n",
       "      <td>1.065060e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36595</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>96</td>\n",
       "      <td>360.998546</td>\n",
       "      <td>520.313613</td>\n",
       "      <td>-1.145422</td>\n",
       "      <td>-0.703820</td>\n",
       "      <td>78.128461</td>\n",
       "      <td>487.628145</td>\n",
       "      <td>458.058551</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7.920819e+06</td>\n",
       "      <td>138.299589</td>\n",
       "      <td>2.620230e+03</td>\n",
       "      <td>1.947443e+06</td>\n",
       "      <td>105.411223</td>\n",
       "      <td>5.738522e+03</td>\n",
       "      <td>1.126734e+07</td>\n",
       "      <td>28.126394</td>\n",
       "      <td>1.757182e+02</td>\n",
       "      <td>2.781661e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36596</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>97</td>\n",
       "      <td>392.702026</td>\n",
       "      <td>522.348411</td>\n",
       "      <td>-1.148606</td>\n",
       "      <td>0.216379</td>\n",
       "      <td>63.044880</td>\n",
       "      <td>458.143799</td>\n",
       "      <td>449.519362</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.064831e+07</td>\n",
       "      <td>88.794129</td>\n",
       "      <td>2.270597e+03</td>\n",
       "      <td>6.343661e+05</td>\n",
       "      <td>51.068321</td>\n",
       "      <td>5.682096e+03</td>\n",
       "      <td>1.064753e+07</td>\n",
       "      <td>14.330537</td>\n",
       "      <td>1.305454e+02</td>\n",
       "      <td>4.452638e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36597</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>98</td>\n",
       "      <td>389.828191</td>\n",
       "      <td>526.828641</td>\n",
       "      <td>-0.930038</td>\n",
       "      <td>-0.102140</td>\n",
       "      <td>53.929362</td>\n",
       "      <td>450.198921</td>\n",
       "      <td>461.853080</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>9.068055e+06</td>\n",
       "      <td>39.005014</td>\n",
       "      <td>1.100892e+03</td>\n",
       "      <td>4.642791e+05</td>\n",
       "      <td>73.961903</td>\n",
       "      <td>5.745381e+03</td>\n",
       "      <td>1.249095e+07</td>\n",
       "      <td>21.871390</td>\n",
       "      <td>3.041467e+02</td>\n",
       "      <td>5.399709e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36598</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>99</td>\n",
       "      <td>416.284422</td>\n",
       "      <td>491.390537</td>\n",
       "      <td>-1.500171</td>\n",
       "      <td>0.009017</td>\n",
       "      <td>44.860950</td>\n",
       "      <td>462.373730</td>\n",
       "      <td>450.518923</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.070457e+07</td>\n",
       "      <td>113.770082</td>\n",
       "      <td>4.705816e+03</td>\n",
       "      <td>6.433879e+06</td>\n",
       "      <td>28.340584</td>\n",
       "      <td>1.119315e+04</td>\n",
       "      <td>5.542648e+07</td>\n",
       "      <td>20.784016</td>\n",
       "      <td>5.197250e+02</td>\n",
       "      <td>1.217503e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36599</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>100</td>\n",
       "      <td>395.222827</td>\n",
       "      <td>496.096870</td>\n",
       "      <td>-1.016045</td>\n",
       "      <td>0.048475</td>\n",
       "      <td>37.907325</td>\n",
       "      <td>446.207972</td>\n",
       "      <td>445.693412</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>9.380197e+07</td>\n",
       "      <td>29.077590</td>\n",
       "      <td>4.485907e+03</td>\n",
       "      <td>1.471306e+07</td>\n",
       "      <td>53.802504</td>\n",
       "      <td>5.173645e+03</td>\n",
       "      <td>1.094524e+07</td>\n",
       "      <td>34.829693</td>\n",
       "      <td>3.883093e+02</td>\n",
       "      <td>1.084026e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36600 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  machineID  rotate_min  rotate_max  rotate_<lambda_0>  \\\n",
       "0      2015-01-01          1  346.149335  527.349825          -0.790617   \n",
       "1      2015-01-01          2  369.738792  543.802540           0.093926   \n",
       "2      2015-01-01          3  382.648588  531.139800          -1.240765   \n",
       "3      2015-01-01          4  327.243866  551.327283           0.721164   \n",
       "4      2015-01-01          5  308.578855  539.732729          -0.368387   \n",
       "...           ...        ...         ...         ...                ...   \n",
       "36595  2016-01-01         96  360.998546  520.313613          -1.145422   \n",
       "36596  2016-01-01         97  392.702026  522.348411          -1.148606   \n",
       "36597  2016-01-01         98  389.828191  526.828641          -0.930038   \n",
       "36598  2016-01-01         99  416.284422  491.390537          -1.500171   \n",
       "36599  2016-01-01        100  395.222827  496.096870          -1.016045   \n",
       "\n",
       "       rotate_<lambda_1>  rotate_<lambda_2>  rotate_median  rotate_mean  \\\n",
       "0               0.156417          78.750562     432.850118   440.515328   \n",
       "1               0.364777          47.779860     444.667492   445.200094   \n",
       "2               0.072763          70.039863     461.496434   454.152365   \n",
       "3               0.150727          43.058493     444.503545   447.758764   \n",
       "4              -0.589313          94.737470     461.502012   450.183235   \n",
       "...                  ...                ...            ...          ...   \n",
       "36595          -0.703820          78.128461     487.628145   458.058551   \n",
       "36596           0.216379          63.044880     458.143799   449.519362   \n",
       "36597          -0.102140          53.929362     450.198921   461.853080   \n",
       "36598           0.009017          44.860950     462.373730   450.518923   \n",
       "36599           0.048475          37.907325     446.207972   445.693412   \n",
       "\n",
       "       rotate_count  ...  fft_pressure_magnitude_energy_  \\\n",
       "0                18  ...                    7.807908e+13   \n",
       "1                18  ...                    8.793219e+07   \n",
       "2                18  ...                    1.933841e+07   \n",
       "3                18  ...                    3.488463e+07   \n",
       "4                18  ...                    1.594540e+07   \n",
       "...             ...  ...                             ...   \n",
       "36595             7  ...                    7.920819e+06   \n",
       "36596             7  ...                    2.064831e+07   \n",
       "36597             7  ...                    9.068055e+06   \n",
       "36598             7  ...                    2.070457e+07   \n",
       "36599             7  ...                    9.380197e+07   \n",
       "\n",
       "       fft_vibration_magnitude_mape_  fft_vibration_magnitude_rmse_  \\\n",
       "0                          34.686905                   8.337336e+06   \n",
       "1                          78.885919                   4.052344e+03   \n",
       "2                          52.362296                   2.165231e+03   \n",
       "3                         157.143177                   3.017703e+03   \n",
       "4                          90.424001                   2.451706e+03   \n",
       "...                              ...                            ...   \n",
       "36595                     138.299589                   2.620230e+03   \n",
       "36596                      88.794129                   2.270597e+03   \n",
       "36597                      39.005014                   1.100892e+03   \n",
       "36598                     113.770082                   4.705816e+03   \n",
       "36599                      29.077590                   4.485907e+03   \n",
       "\n",
       "       fft_vibration_magnitude_energy_  fft_volt_magnitude_mape_  \\\n",
       "0                         1.251839e+13                 50.344818   \n",
       "1                         1.461031e+07                 59.472938   \n",
       "2                         3.243161e+06                 51.215365   \n",
       "3                         4.651890e+06                 43.115204   \n",
       "4                         4.864141e+06                 65.013985   \n",
       "...                                ...                       ...   \n",
       "36595                     1.947443e+06                105.411223   \n",
       "36596                     6.343661e+05                 51.068321   \n",
       "36597                     4.642791e+05                 73.961903   \n",
       "36598                     6.433879e+06                 28.340584   \n",
       "36599                     1.471306e+07                 53.802504   \n",
       "\n",
       "       fft_volt_magnitude_rmse_  fft_volt_magnitude_energy_  \\\n",
       "0                  3.526230e+07                2.238566e+14   \n",
       "1                  1.233967e+04                1.327563e+08   \n",
       "2                  6.231189e+03                4.040704e+07   \n",
       "3                  5.029131e+03                2.867365e+07   \n",
       "4                  5.540018e+03                3.057701e+07   \n",
       "...                         ...                         ...   \n",
       "36595              5.738522e+03                1.126734e+07   \n",
       "36596              5.682096e+03                1.064753e+07   \n",
       "36597              5.745381e+03                1.249095e+07   \n",
       "36598              1.119315e+04                5.542648e+07   \n",
       "36599              5.173645e+03                1.094524e+07   \n",
       "\n",
       "       signal_mag_area_mape_  signal_mag_area_rmse_  signal_mag_area_energy_  \n",
       "0                  31.095042           1.566259e+06             4.417369e+11  \n",
       "1                  21.840449           3.890529e+02             2.483783e+05  \n",
       "2                  26.900778           2.764719e+02             1.199865e+05  \n",
       "3                  22.249581           2.267437e+02             1.382671e+05  \n",
       "4                  25.863185           2.079213e+02             1.065060e+05  \n",
       "...                      ...                    ...                      ...  \n",
       "36595              28.126394           1.757182e+02             2.781661e+04  \n",
       "36596              14.330537           1.305454e+02             4.452638e+04  \n",
       "36597              21.871390           3.041467e+02             5.399709e+04  \n",
       "36598              20.784016           5.197250e+02             1.217503e+05  \n",
       "36599              34.829693           3.883093e+02             1.084026e+05  \n",
       "\n",
       "[36600 rows x 89 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Group the DataFrame by 'date' and 'machineID'\n",
    "grouped_data = df.groupby(['date', 'machineID'])\n",
    "\n",
    "# Step 2: Apply aggregation functions on sensor columns for each group\n",
    "aggregated_data = grouped_data.agg({\n",
    "    'rotate': ['min', 'max', lambda x: kurtosis(x), lambda x: skew(x), lambda x: x.quantile(0.75) - x.quantile(0.25), 'median', 'mean','count'],\n",
    "    'volt': ['min', 'max', lambda x: kurtosis(x), lambda x: skew(x), lambda x: x.quantile(0.75) - x.quantile(0.25), 'median', 'mean','count'],\n",
    "    'pressure': ['min', 'max', lambda x: kurtosis(x), lambda x: skew(x), lambda x: x.quantile(0.75) - x.quantile(0.25), 'median', 'mean','count'],\n",
    "    'vibration': ['min', 'max', lambda x: kurtosis(x), lambda x: skew(x), lambda x: x.quantile(0.75) - x.quantile(0.25), 'median', 'mean','count'],\n",
    "    'fft_rotate_magnitude': ['min', 'max',lambda x: skew(x), lambda x: x.quantile(0.75) - x.quantile(0.25), 'median', 'mean','count'],\n",
    "    'fft_pressure_magnitude': ['min', 'max',lambda x: skew(x), lambda x: x.quantile(0.75) - x.quantile(0.25), 'median', 'mean','count'],\n",
    "    'fft_vibration_magnitude': ['min', 'max',lambda x: skew(x), lambda x: x.quantile(0.75) - x.quantile(0.25), 'median', 'mean','count'],\n",
    "    'fft_volt_magnitude': ['min', 'max',lambda x: skew(x), lambda x: x.quantile(0.75) - x.quantile(0.25), 'median', 'mean','count']\n",
    "})\n",
    "\n",
    "# Add point MAPE, RMSE, cross-correlation, energy, and frequency domain features\n",
    "for sensor in ['rotate','volt','pressure','vibration','fft_rotate_magnitude','fft_pressure_magnitude','fft_vibration_magnitude','fft_volt_magnitude','signal_mag_area']:\n",
    "    aggregated_data[sensor + '_mape'] = grouped_data[sensor].apply(lambda x: mape(x, x.median()))\n",
    "    aggregated_data[sensor + '_rmse'] = grouped_data[sensor].apply(lambda x: rmse(x, x.median()))\n",
    "    aggregated_data[sensor + '_energy'] = grouped_data[sensor].apply(lambda x: energy(x))\n",
    "\n",
    "# Step 3: Flatten the multi-level column index\n",
    "aggregated_data.columns = ['_'.join(col).strip() for col in aggregated_data.columns.values]\n",
    "\n",
    "# Optionally, you can reset the index to get 'date' and 'machineID' as separate columns\n",
    "aggregated_data.reset_index(inplace=True)\n",
    "\n",
    "aggregated_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************************************************************************************************************************************\n",
      "Shape of left dataset:                              (36600, 91)\n",
      "Shape of the right dataset:                         (3919, 4)\n",
      "Shape of merged dataset before checking duplicates: (37078, 93)\n",
      "Duplicate rows found: 422\n",
      "Duplicates rows removed: 211.0\n",
      "Shape of merged dataset after removing duplicate columns: (36600, 94)\n",
      "********************************************************************************************************************************************************************************************************\n",
      "Shape of left dataset:                              (36600, 94)\n",
      "Shape of the right dataset:                         (3286, 4)\n",
      "Shape of merged dataset before checking duplicates: (37323, 96)\n",
      "Duplicate rows found: 723\n",
      "Duplicates rows removed: 361.5\n",
      "Shape of merged dataset after removing duplicate columns: (36600, 96)\n",
      "********************************************************************************************************************************************************************************************************\n",
      "Shape of left dataset:                              (36600, 96)\n",
      "Shape of the right dataset:                         (761, 4)\n",
      "Shape of merged dataset before checking duplicates: (36643, 98)\n",
      "Duplicate rows found: 43\n",
      "Duplicates rows removed: 21.5\n",
      "Shape of merged dataset after removing duplicate columns: (36600, 98)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>machineID</th>\n",
       "      <th>rotate_min</th>\n",
       "      <th>rotate_max</th>\n",
       "      <th>rotate_&lt;lambda_0&gt;</th>\n",
       "      <th>rotate_&lt;lambda_1&gt;</th>\n",
       "      <th>rotate_&lt;lambda_2&gt;</th>\n",
       "      <th>rotate_median</th>\n",
       "      <th>rotate_mean</th>\n",
       "      <th>rotate_count</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_mag_area_energy_</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "      <th>datetime_x</th>\n",
       "      <th>errorID</th>\n",
       "      <th>combo</th>\n",
       "      <th>datetime_y</th>\n",
       "      <th>comp</th>\n",
       "      <th>datetime</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>346.149335</td>\n",
       "      <td>527.349825</td>\n",
       "      <td>-0.790617</td>\n",
       "      <td>0.156417</td>\n",
       "      <td>78.750562</td>\n",
       "      <td>432.850118</td>\n",
       "      <td>440.515328</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>4.417369e+11</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1~2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>369.738792</td>\n",
       "      <td>543.802540</td>\n",
       "      <td>0.093926</td>\n",
       "      <td>0.364777</td>\n",
       "      <td>47.779860</td>\n",
       "      <td>444.667492</td>\n",
       "      <td>445.200094</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>2.483783e+05</td>\n",
       "      <td>model4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2~2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>382.648588</td>\n",
       "      <td>531.139800</td>\n",
       "      <td>-1.240765</td>\n",
       "      <td>0.072763</td>\n",
       "      <td>70.039863</td>\n",
       "      <td>461.496434</td>\n",
       "      <td>454.152365</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.199865e+05</td>\n",
       "      <td>model3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3~2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>327.243866</td>\n",
       "      <td>551.327283</td>\n",
       "      <td>0.721164</td>\n",
       "      <td>0.150727</td>\n",
       "      <td>43.058493</td>\n",
       "      <td>444.503545</td>\n",
       "      <td>447.758764</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.382671e+05</td>\n",
       "      <td>model3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4~2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>308.578855</td>\n",
       "      <td>539.732729</td>\n",
       "      <td>-0.368387</td>\n",
       "      <td>-0.589313</td>\n",
       "      <td>94.737470</td>\n",
       "      <td>461.502012</td>\n",
       "      <td>450.183235</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065060e+05</td>\n",
       "      <td>model3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5~2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  machineID  rotate_min  rotate_max  rotate_<lambda_0>  \\\n",
       "0  2015-01-01          1  346.149335  527.349825          -0.790617   \n",
       "1  2015-01-01          2  369.738792  543.802540           0.093926   \n",
       "2  2015-01-01          3  382.648588  531.139800          -1.240765   \n",
       "3  2015-01-01          4  327.243866  551.327283           0.721164   \n",
       "4  2015-01-01          5  308.578855  539.732729          -0.368387   \n",
       "\n",
       "   rotate_<lambda_1>  rotate_<lambda_2>  rotate_median  rotate_mean  \\\n",
       "0           0.156417          78.750562     432.850118   440.515328   \n",
       "1           0.364777          47.779860     444.667492   445.200094   \n",
       "2           0.072763          70.039863     461.496434   454.152365   \n",
       "3           0.150727          43.058493     444.503545   447.758764   \n",
       "4          -0.589313          94.737470     461.502012   450.183235   \n",
       "\n",
       "   rotate_count  ...  signal_mag_area_energy_   model  age  datetime_x  \\\n",
       "0            18  ...             4.417369e+11  model3   18           0   \n",
       "1            18  ...             2.483783e+05  model4    7           0   \n",
       "2            18  ...             1.199865e+05  model3    8           0   \n",
       "3            18  ...             1.382671e+05  model3    7           0   \n",
       "4            18  ...             1.065060e+05  model3    2           0   \n",
       "\n",
       "   errorID         combo  datetime_y  comp  datetime  failure  \n",
       "0        0  1~2015-01-01           0     0         0        0  \n",
       "1        0  2~2015-01-01           0     0         0        0  \n",
       "2        0  3~2015-01-01           0     0         0        0  \n",
       "3        0  4~2015-01-01           0     0         0        0  \n",
       "4        0  5~2015-01-01           0     0         0        0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aggregated_data.to_csv('aggregated.csv')\n",
    "df_agg = aggregated_data.copy()\n",
    "\n",
    "\n",
    "def merger_with_duplicate_row_remover(df1 , df2 ):\n",
    "    print(\"*\"*200)\n",
    "    if (\"date\" in df2.columns):\n",
    "        merged_df =pd.merge(df1, df2, on=['date','machineID'],how='left')\n",
    "        merged_df = merged_df.replace(np.NaN,0)\n",
    "        print(\"Shape of left dataset:                             \",df1.shape)\n",
    "        print(\"Shape of the right dataset:                        \",df2.shape)\n",
    "        print(\"Shape of merged dataset before checking duplicates:\",merged_df.shape)\n",
    "\n",
    "        #creating an extra column that will have unique datetime+machineID\n",
    "        merged_df['combo'] = merged_df['machineID'].astype(str) +\"~\"+ merged_df['date'].astype(str) \n",
    "        # merged_df['combo'].value_counts() to check duplicates Anything greater than 1 will be duplicated\n",
    "        li = merged_df['combo'].value_counts()\n",
    "        valids = li[li > 1].index  \n",
    "        print(\"Duplicate rows found:\", len(valids))\n",
    "\n",
    "        merged_df[merged_df['combo'].isin(valids)] #create a dataframe To get rows of deficit indices\n",
    "        # Here dropping the duplicate rows becomes essential \n",
    "        merged_df = merged_df.drop_duplicates(subset=['combo']) \n",
    "        print(\"Duplicates rows removed:\", len(valids)/2 )\n",
    "        print(\"Shape of merged dataset after removing duplicate columns:\", merged_df.shape)\n",
    "    else:\n",
    "        # Machine dataframe has no datatime plus no duplicates\n",
    "        merged_df =pd.merge(df1, df2, on=['machineID'],how='left')\n",
    "        merged_df = merged_df.replace(np.NaN,0)\n",
    "        print(\"Shape of left dataset:                             \",df1.shape)\n",
    "        print(\"Shape of the right dataset:                        \",df2.shape)\n",
    "        print(\"Shape of merged dataset before checking duplicates:\",merged_df.shape)\n",
    "        \n",
    "    return merged_df\n",
    "\n",
    "err = df_errors.copy()\n",
    "err['datetime'] = pd.to_datetime(err['datetime'])\n",
    "err['date'] = err['datetime'].dt.date\n",
    "maint = df_maint.copy()\n",
    "maint['datetime'] = pd.to_datetime(maint['datetime'])\n",
    "maint['date'] = maint['datetime'].dt.date\n",
    "\n",
    "fail = df_failure.copy()\n",
    "fail['datetime'] = pd.to_datetime(fail['datetime'])\n",
    "fail['date'] = fail['datetime'].dt.date\n",
    "\n",
    "data = pd.merge(df_agg, df_machines, how= 'left', on='machineID')\n",
    "data = merger_with_duplicate_row_remover(data,err)\n",
    "data = merger_with_duplicate_row_remover(data,maint)\n",
    "data = merger_with_duplicate_row_remover(data,fail)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' 'comp1' 'comp4' 'comp3' 'comp2']\n"
     ]
    }
   ],
   "source": [
    "#Further target column will be transformed with label encoding ,and other categorical columns with dummy encoding \n",
    "\n",
    "data_encoded = pd.get_dummies(data, columns=['comp', 'errorID', 'model'], drop_first=True)\n",
    "data_encoded = data_encoded.replace({'failure' : 0}, '0')\n",
    "print(data_encoded.failure.unique()) #To verify the change \n",
    "data_encoded.head(2)\n",
    "data_encoded.drop([\"combo\",\"datetime_x\", 'datetime_y','datetime'] , axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get X_train and y_train : original training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_encoded.drop(['failure','date'], axis=1), data_encoded['failure'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the data into training set and validation set (80% training, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.18, random_state=42)\n",
    "\n",
    "# Now we have X_train and y_train as the new training set, and X_val and y_val as the validation set.\n",
    "\n",
    "# Fit the encoder on y_train to learn the mapping\n",
    "enc = LabelEncoder()\n",
    "enc.fit(y_train)\n",
    "enc.fit(y_val)\n",
    "\n",
    "y_train = enc.transform(y_train)\n",
    "y_test = enc.transform(y_test)\n",
    "y_val_encoded = enc.transform(y_val)\n",
    "\n",
    "#Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Evaluation:\n",
      "Accuracy:  0.9893758300132802\n",
      "Precision:  0.7629240169764507\n",
      "Recall:  0.6915949178151\n",
      "F1:  0.7182985952330304\n",
      "Confusion Matrix:\n",
      "[[5159    6    8    4    1]\n",
      " [  10    9    1    2    0]\n",
      " [  12    0   17    0    0]\n",
      " [   3    0    0   13    0]\n",
      " [   7    1    1    0   17]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      5178\n",
      "           1       0.56      0.41      0.47        22\n",
      "           2       0.63      0.59      0.61        29\n",
      "           3       0.68      0.81      0.74        16\n",
      "           4       0.94      0.65      0.77        26\n",
      "\n",
      "    accuracy                           0.99      5271\n",
      "   macro avg       0.76      0.69      0.72      5271\n",
      "weighted avg       0.99      0.99      0.99      5271\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy:  0.9901639344262295\n",
      "Precision:  0.7812758397932816\n",
      "Recall:  0.7340519549271931\n",
      "F1:  0.7518573959815164\n",
      "Confusion Matrix:\n",
      "[[7162    8   16    2    1]\n",
      " [  19   16    0    1    0]\n",
      " [  10    0   27    1    3]\n",
      " [   2    0    0   27    0]\n",
      " [   7    1    0    1   16]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7189\n",
      "           1       0.64      0.44      0.52        36\n",
      "           2       0.63      0.66      0.64        41\n",
      "           3       0.84      0.93      0.89        29\n",
      "           4       0.80      0.64      0.71        25\n",
      "\n",
      "    accuracy                           0.99      7320\n",
      "   macro avg       0.78      0.73      0.75      7320\n",
      "weighted avg       0.99      0.99      0.99      7320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "# Create and train the Logistic Regression model\n",
    "mdl = LogisticRegression(max_iter=8000)\n",
    "mdl.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = mdl.predict(X_val) \n",
    "y_val_pred_prob = mdl.predict_proba(X_val)[:,1]    # Predicts the probability of the validation data\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "print(\"Validation Set Evaluation:\")\n",
    "print(\"Accuracy: \", accuracy_score(y_val_encoded, y_val_pred))\n",
    "print(\"Precision: \", precision_score(y_val_encoded, y_val_pred, average='macro'))\n",
    "print(\"Recall: \", recall_score(y_val_encoded, y_val_pred, average='macro'))\n",
    "print(\"F1: \", f1_score(y_val_encoded, y_val_pred, average='macro'))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val_encoded, y_val_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val_encoded, y_val_pred))\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = mdl.predict(X_test) \n",
    "y_test_pred_prob = mdl.predict_proba(X_test)[:,1]    # Predicts the probability of the test data\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"Test Set Evaluation:\")\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_test_pred, average='macro'))\n",
    "print(\"Recall: \", recall_score(y_test, y_test_pred, average='macro'))\n",
    "print(\"F1: \", f1_score(y_test, y_test_pred, average='macro'))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20968/569370423.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Assuming you have the features (X_train) and labels (y_train) ready in a DataFrame format\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define the parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'eval_metric': ['logloss', 'error', 'auc'],  # Define multiple evaluation metrics\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_rounds = 100\n",
    "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_probs = xgb_model.predict(dtest)\n",
    "y_pred = [1 if prob >= 0.5 else 0 for prob in y_pred_probs]\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_probs)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
