{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import constants\n",
    "import math\n",
    "import scipy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def various_data_info(df):\n",
    "    print(df.describe())\n",
    "    print(df.isna().sum())\n",
    "    print(df.info())\n",
    "\n",
    "def merger_with_duplicate_row_remover(df1 , df2 ):\n",
    "    print(\"*\"*100)\n",
    "    if (\"datetime\" in df2.columns):\n",
    "        merged_df =pd.merge(df1, df2, on=['datetime','machineID'],how='left')\n",
    "        merged_df = merged_df.replace(np.NaN,0)\n",
    "        print(\"Shape of left dataset:                             \",df1.shape)\n",
    "        print(\"Shape of the right dataset:                        \",df2.shape)\n",
    "        print(\"Shape of merged dataset before checking duplicates:\",merged_df.shape)\n",
    "\n",
    "        #creating an extra column that will have unique datetime+machineID\n",
    "        merged_df['combo'] = merged_df['machineID'].astype(str) + merged_df['datetime'].astype(str) \n",
    "        # merged_df['combo'].value_counts() to check duplicates Anything greater than 1 will be duplicated\n",
    "        li = merged_df['combo'].value_counts()\n",
    "        valids = li[li > 1].index  \n",
    "        print(\"Duplicate rows found:\", len(valids))\n",
    "\n",
    "        merged_df[merged_df['combo'].isin(valids)] #create a dataframe To get rows of deficit indices\n",
    "        # Here dropping the duplicate rows becomes essential \n",
    "        merged_df = merged_df.drop_duplicates(subset=['combo']) \n",
    "        print(\"Duplicates rows removed:\", len(valids)/2 )\n",
    "        print(\"Shape of merged dataset after removing duplicate columns:\", merged_df.shape)\n",
    "    else:\n",
    "        # Machine dataframe has no datatime plus no duplicates\n",
    "        merged_df =pd.merge(df1, df2, on=['machineID'],how='left')\n",
    "        merged_df = merged_df.replace(np.NaN,0)\n",
    "        print(\"Shape of left dataset:                             \",df1.shape)\n",
    "        print(\"Shape of the right dataset:                        \",df2.shape)\n",
    "        print(\"Shape of merged dataset before checking duplicates:\",merged_df.shape)\n",
    "        \n",
    "    return merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failure = pd.read_csv('PdM_failures.csv')\n",
    "df_errors = pd.read_csv('PdM_errors.csv')\n",
    "df_machines = pd.read_csv('PdM_machines.csv')\n",
    "df_maint = pd.read_csv('PdM_maint.csv')\n",
    "df_telemetry = pd.read_csv('PdM_telemetry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Shape of left dataset:                              (876100, 6)\n",
      "Shape of the right dataset:                         (761, 3)\n",
      "Shape of merged dataset before checking duplicates: (876142, 7)\n",
      "Duplicate rows found: 42\n",
      "Duplicates rows removed: 21.0\n",
      "Shape of merged dataset after removing duplicate columns: (876100, 8)\n",
      "****************************************************************************************************\n",
      "Shape of left dataset:                              (876100, 8)\n",
      "Shape of the right dataset:                         (3919, 3)\n",
      "Shape of merged dataset before checking duplicates: (876403, 9)\n",
      "Duplicate rows found: 274\n",
      "Duplicates rows removed: 137.0\n",
      "Shape of merged dataset after removing duplicate columns: (876100, 9)\n",
      "****************************************************************************************************\n",
      "Shape of left dataset:                              (876100, 9)\n",
      "Shape of the right dataset:                         (3286, 3)\n",
      "Shape of merged dataset before checking duplicates: (876823, 10)\n",
      "Duplicate rows found: 723\n",
      "Duplicates rows removed: 361.5\n",
      "Shape of merged dataset after removing duplicate columns: (876100, 10)\n",
      "****************************************************************************************************\n",
      "Shape of left dataset:                              (876100, 10)\n",
      "Shape of the right dataset:                         (100, 3)\n",
      "Shape of merged dataset before checking duplicates: (876100, 12)\n"
     ]
    }
   ],
   "source": [
    "df_list = [df_failure, df_errors, df_maint, df_machines]  \n",
    "df_merged = df_telemetry.copy()\n",
    "for i in df_list:\n",
    "    df_merged = merger_with_duplicate_row_remover(df_merged,i)\n",
    "\n",
    "df_merged = df_merged.rename(columns={'comp':'maint_comp'}) \n",
    "\n",
    "#df_merged['failure'] = pd.Categorical(df_merged['failure'])\n",
    "df_merged['errorID'] = pd.Categorical(df_merged['errorID'])\n",
    "df_merged['maint_comp'] = pd.Categorical(df_merged['maint_comp'])\n",
    "\n",
    "df = df_merged.copy()\n",
    "\n",
    "df['datetime'] = df['datetime'].astype(\"datetime64[ns]\")\n",
    "# Extract features from timestamp\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['year'] = df['datetime'].dt.year\n",
    "df['date'] = df['datetime'].dt.date\n",
    "df['time'] = df['datetime'].dt.time\n",
    "# \n",
    "df['rotate_in_radians'] = (df['rotate'] * np.pi/180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         7.304274\n",
       "1         7.029270\n",
       "2         9.203991\n",
       "3         6.041446\n",
       "4         7.598760\n",
       "            ...   \n",
       "876095    6.897940\n",
       "876096    7.787798\n",
       "876097    7.815873\n",
       "876098    7.221678\n",
       "876099    8.658524\n",
       "Name: rotate, Length: 876100, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotation = np.deg2rad( df_telemetry['rotate'])\n",
    "rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         7.304274\n",
       "1         7.029270\n",
       "2         9.203991\n",
       "3         6.041446\n",
       "4         7.598760\n",
       "            ...   \n",
       "876095    6.897940\n",
       "876096    7.787798\n",
       "876097    7.815873\n",
       "876098    7.221678\n",
       "876099    8.658524\n",
       "Name: rotate, Length: 876100, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotation2 = (df_telemetry['rotate'] * (np.pi/180))\n",
    "rotation2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volt',\n",
       " 'rotate',\n",
       " 'pressure',\n",
       " 'vibration',\n",
       " 'age',\n",
       " 'hour',\n",
       " 'day_of_week',\n",
       " 'month',\n",
       " 'year']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby(['machineID', 'date']).mean() \n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22524/1611236809.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#Create overlapping window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mvolt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'volt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m24\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mrotate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rotate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m24\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "#https://towardsdatascience.com/feature-engineering-on-time-series-data-transforming-signal-data-of-a-smartphone-accelerometer-for-72cbe34b8a60\n",
    "list_volt = []\n",
    "list_rotate = []\n",
    "list_pressure = []\n",
    "list_vibration = []\n",
    "train_labels = []\n",
    "\n",
    "window_size = 24\n",
    "step_size = 7\n",
    "\n",
    "#Create overlapping window\n",
    "for i in range(0, df_train.shape[0] - window_size, step_size):\n",
    "    volt = df_train['volt'].values[i: i + 24]\n",
    "    rotate = df_train['rotate'].values[i: i + 24]\n",
    "    pressure = df_train[\"pressure\"].values[i: i + 24]\n",
    "    vibration = df_train['vibration'].values[i: i + 24]\n",
    "    #label = stats.mode(df_train['failure'][i: i + 100])[0]\n",
    "\n",
    "    list_volt.append(volt)\n",
    "    list_rotate.append(rotate)\n",
    "    list_pressure.append(pressure)\n",
    "    list_vibration.append(vibration)\n",
    "    #train_labels.append(label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing \n",
    "Null Hypothesis: The sample data is from the original distribution (nothing interesting is going on; in other words the received data is based on the underlying population)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame() \n",
    "\n",
    "# min\n",
    "x_train['volt_min'] = pd.Series(list_volt).apply(lambda x: x.min())\n",
    "x_train['rotate_min'] = pd.Series(list_rotate).apply(lambda x: x.min())\n",
    "x_train['pressure_min'] = pd.Series(list_pressure).apply(lambda x: x.min())\n",
    "x_train['vibration_min'] = pd.Series(list_vibration).apply(lambda x: x.min())\n",
    "\n",
    "\n",
    "# max \n",
    "x_train['volt_max'] = pd.Series(list_volt).apply(lambda x: x.max())\n",
    "x_train['rotate_max'] = pd.Series(list_rotate).apply(lambda x: x.max())\n",
    "x_train['pressure_max'] = pd.Series(list_pressure).apply(lambda x: x.max())\n",
    "x_train['vibration_max'] = pd.Series(list_vibration).apply(lambda x: x.max())\n",
    "\n",
    "# Interquartile  range\n",
    "x_train['volt_IQR'] = pd.Series(list_volt).apply(lambda x: np.percentile(x,75) - np.percentile(x,25))\n",
    "x_train['rotate_IQR'] = pd.Series(list_rotate).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "x_train['pressure_IQR'] = pd.Series(list_pressure).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "x_train['vibration_IQR'] = pd.Series(list_vibration).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "\n",
    "# median\n",
    "x_train['volt_median'] = pd.Series(list_volt).apply(lambda x: np.median(x))\n",
    "x_train['rotate_median'] = pd.Series(list_rotate).apply(lambda x: np.median(x))\n",
    "x_train['pressure_median'] = pd.Series(list_pressure).apply(lambda x: np.median(x))\n",
    "x_train['vibration_median'] = pd.Series(list_vibration).apply(lambda x: np.median(x))\n",
    "\n",
    "# mean \n",
    "x_train['volt_mean'] = pd.Series(list_volt).apply(lambda x: x.mean())\n",
    "x_train['rotate_mean'] = pd.Series(list_rotate).apply(lambda x: x.mean())\n",
    "x_train['pressure_mean'] = pd.Series(list_pressure).apply(lambda x: x.mean())\n",
    "x_train['vibration_mean'] = pd.Series(list_vibration).apply(lambda x: x.mean())\n",
    "\n",
    "# std\n",
    "x_train['volt_std'] = pd.Series(list_volt).apply(lambda x: x.std())\n",
    "x_train['rotate_std'] = pd.Series(list_rotate).apply(lambda x: x.std())\n",
    "x_train['pressure_std'] = pd.Series(list_pressure).apply(lambda x: x.std())\n",
    "x_train['vibration_std'] = pd.Series(list_vibration).apply(lambda x: x.std())\n",
    "\n",
    "# peaks\n",
    "x_train['volt_peaks'] = pd.Series(list_volt).apply(lambda x: len(find_peaks(x)[0]))\n",
    "x_train['rotate_peaks'] = pd.Series(list_rotate).apply(lambda x: len(find_peaks(x)[0]))\n",
    "x_train['pressure_peaks'] = pd.Series(list_pressure).apply(lambda x: len(find_peaks(x)[0]))\n",
    "x_train['vibration_peaks'] = pd.Series(list_vibration).apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "# skewness\n",
    "x_train['volt_skewness'] = pd.Series(list_volt).apply(lambda x: stats.skew(x))\n",
    "x_train['rotate_skewness'] = pd.Series(list_rotate).apply(lambda x: stats.skew(x))\n",
    "x_train['pressure_skewness'] = pd.Series(list_pressure).apply(lambda x: stats.skew(x))\n",
    "x_train['vibration_skewness'] = pd.Series(list_vibration).apply(lambda x: stats.skew(x))\n",
    "\n",
    "# Kurtosis \n",
    "x_train['volt_kurtosis'] = pd.Series(list_volt).apply(lambda x: stats.kurtosis(x))\n",
    "x_train['rotate_kurtosis'] = pd.Series(list_rotate).apply(lambda x: stats.kurtosis(x))\n",
    "x_train['pressure_kurtosis'] = pd.Series(list_pressure).apply(lambda x: stats.kurtosis(x))\n",
    "x_train['vibration_kurtosis'] = pd.Series(list_vibration).apply(lambda x: stats.kurtosis(x))\n",
    "\n",
    "# Signal Magnitude Area\n",
    "x_train['sma'] = pd.Series(list_volt).apply(lambda x: np.sum(abs(x)/100)) \\\n",
    "    + pd.Series(list_rotate.apply(lambda x: np.sum(abs(x)/100)) + pd.Series(list_pressure).apply(lambda x: np.sum(abs(x)/100)) \\\n",
    "    + pd.Series(list_vibration).apply(lambda x: np.sum(abs(x)/100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_22524/609024811.py:2: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  sma = pd.Series(list_volt).apply(lambda x: np.sum(abs(x)/100)) + pd.Series(list_rotate).apply(lambda x: np.sum(abs(x)/100)) + pd.Series(list_pressure).apply(lambda x: np.sum(abs(x)/100)) + pd.Series(list_vibration).apply(lambda x: np.sum(abs(x)/100))\n"
     ]
    }
   ],
   "source": [
    "# Signal Magnitude Area\n",
    "sma = pd.Series(list_volt).apply(lambda x: np.sum(abs(x)/100)) + pd.Series(list_rotate).apply(lambda x: np.sum(abs(x)/100)) + pd.Series(list_pressure).apply(lambda x: np.sum(abs(x)/100)) + pd.Series(list_vibration).apply(lambda x: np.sum(abs(x)/100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have the rotation column given in RPM (rotations per minute) on an hourly basis and you want to derive the velocity values, you can use the following steps:\n",
    "\n",
    "Convert RPM to Rotations per Second: Since the rotation values are given in RPM, you need to convert them to rotations per second (RPS) to align with the time unit. Divide the RPM values by 60 to convert them to RPS.\n",
    "\n",
    "Convert Rotations per Second to Angular Velocity: Angular velocity is the rate of change of angle with respect to time. Multiply the RPS values by 2π to obtain the angular velocity values in radians per second.\n",
    "\n",
    "Calculate Linear Velocity: If you know the radius of the rotating object, you can calculate linear velocity based on the angular velocity. Multiply the angular velocity values by the radius to obtain the linear velocity values.\n",
    "\n",
    "Here's an example implementation in Python assuming you have a DataFrame named df with a column named 'rotation' containing the rotation values in RPM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2060/621698920.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert RPM to RPS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rotation_rps'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rotate'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Convert RPS to angular velocity in radians per second\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'angular_velocity'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rotation_rps'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert RPM to RPS\n",
    "df['rotation_rps'] = df['rotate'] / 60\n",
    "\n",
    "# Convert RPS to angular velocity in radians per second\n",
    "df['angular_velocity'] = df['rotation_rps'] * 2 * np.pi\n",
    "\n",
    "# Calculate linear velocity assuming a given radius (replace radius with the actual value)\n",
    "radius = 0.5  # Example radius in meters\n",
    "df['linear_velocity'] = df['angular_velocity'] * radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
